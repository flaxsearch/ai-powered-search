{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Semantic Knowledge Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "sys.path.append(\"webserver\")\n",
    "\n",
    "from aips import get_engine, get_semantic_knowledge_graph as get_skg\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()\n",
    "\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s generate_request_root,generate_facets,default_node_name,validate_skg_request_input,generate_request,transform_node,transform_response_facet,sort_by_relatedness_desc,traverse engine/solr/skg\n",
    "def generate_request_root():\n",
    "    return {\n",
    "        \"limit\": 0,\n",
    "        \"params\": {\n",
    "            \"q\": \"*:*\",\n",
    "            \"fore\": \"{!${defType} v=$q}\",\n",
    "            \"back\": \"*:*\",\n",
    "            \"defType\": \"edismax\"\n",
    "        },\n",
    "        \"facet\": {}\n",
    "    }\n",
    "\n",
    "def generate_facets(name=None, values=None, field=None,\n",
    "                    min_occurrences=None, limit=None,\n",
    "                    min_popularity=None, default_operator=\"AND\"):\n",
    "    base_facet = {\"type\": \"query\" if values else \"terms\",\n",
    "                  \"limit\": limit if limit else 10,\n",
    "                  \"sort\": { \"relatedness\": \"desc\" },\n",
    "                  \"facet\": {\n",
    "                      \"relatedness\": {\n",
    "                          \"type\": \"func\",\n",
    "                          \"func\": \"relatedness($fore,$back)\"}}}\n",
    "    if min_occurrences:\n",
    "        base_facet[\"mincount\"] = min_occurrences\n",
    "    if min_popularity:\n",
    "        base_facet[\"facet\"][\"relatedness\"][\"min_popularity\"] = min_popularity\n",
    "    if field:\n",
    "        base_facet[\"field\"] = field\n",
    "    facets = []\n",
    "    if values:\n",
    "        if min_occurrences: base_facet.pop(\"mincount\")\n",
    "        if not limit: base_facet.pop(\"limit\")\n",
    "        for i, _ in enumerate(values):\n",
    "            facets.append(base_facet.copy())\n",
    "            facets[i][\"query\"] = \"{\" + f'!edismax q.op={default_operator} qf={field} v=${name}_{i}_query' + \"}\"\n",
    "    else:\n",
    "        facets = [base_facet]\n",
    "    return facets\n",
    "\n",
    "def default_node_name(i, j):\n",
    "    return \"f\" + str(i) + (f\"_{j}\" if j else \"\")\n",
    "\n",
    "def validate_skg_request_input(multi_node):\n",
    "    if isinstance(multi_node, list):\n",
    "        map(validate_skg_request_input, multi_node)\n",
    "        node_names = [node[\"name\"] for node in multi_node]\n",
    "        if len(node_names) != len(set(node_names)):\n",
    "            raise ValueError(\"Node names must be distinct on a given level.\")\n",
    "    if \"field\" not in multi_node: # and \"values\" in multi_node\n",
    "        raise ValueError(\"'field' must be provided\")\n",
    "\n",
    "def transform_request(*multi_nodes):\n",
    "    \"\"\"Generates a faceted Solr SKG request from a set of multi-nodes. \n",
    "       A multi-node can be a single node or a collection of nodes.\n",
    "       A node can contain the following params: `name`, `values`, `field`, `min_occurance` and `limit`.\n",
    "       :param str name: An optional name of the node. If not provided a default will be assigned\n",
    "       :param list of str value: If empty or absent, a terms facet is used. Otherwise a query facet per value is used\n",
    "       :param str field: The field to query against or discover values from.\n",
    "       :param int min_occurance: The mincount on the facet.\n",
    "       :param int limit: The limit on the facet.\n",
    "       Each subsequent node is applied as a nested facet to all parent facets.\"\"\"\n",
    "    map(validate_skg_request_input, multi_nodes)\n",
    "    request = generate_request_root()\n",
    "    parent_nodes = [request]\n",
    "    for i, multi_node in enumerate(multi_nodes):\n",
    "        current_facets = []\n",
    "        if isinstance(multi_node, dict):\n",
    "            multi_node = [multi_node]   \n",
    "        for j, node in enumerate(multi_node):\n",
    "            if \"name\" not in node:\n",
    "                node[\"name\"] = default_node_name(i, j)\n",
    "            facets = generate_facets(**node)\n",
    "            current_facets.extend(facets)\n",
    "            for i, parent_node in enumerate(parent_nodes):\n",
    "                for j, facet in enumerate(facets):\n",
    "                    parent_node[\"facet\"][f'{node[\"name\"]}_{j}'] = facet\n",
    "            if \"values\" in node:\n",
    "                for i, value in enumerate(node[\"values\"]):\n",
    "                    request[\"params\"][f'{node[\"name\"]}_{i}_query'] = value\n",
    "        parent_nodes = current_facets\n",
    "    return request\n",
    "\n",
    "def transform_node(node, response_params):\n",
    "    relatedness = node[\"relatedness\"][\"relatedness\"] if node[\"count\"] > 0 else 0.0\n",
    "    value_node = {\"relatedness\": relatedness}\n",
    "    sub_traversals = transform_response_facet(node, response_params)\n",
    "    if sub_traversals:\n",
    "        value_node[\"traversals\"] = sub_traversals\n",
    "    return value_node\n",
    "\n",
    "def transform_response_facet(node, response_params):\n",
    "    ignored_keys = [\"count\", \"relatedness\", \"val\"]\n",
    "    traversals = {}\n",
    "    for full_name, data in node.items():\n",
    "        if full_name in ignored_keys:\n",
    "            continue\n",
    "        name = full_name.removesuffix(\"_\" + full_name.split(\"_\")[-1])\n",
    "        if name not in traversals:\n",
    "            traversals[name] = {\"name\": name, \"values\": {}}\n",
    "        if \"buckets\" in data:\n",
    "            values_node = {b[\"val\"] : transform_node(b, response_params)\n",
    "                           for b in data[\"buckets\"]}\n",
    "            traversals[name][\"values\"] = values_node\n",
    "        else:\n",
    "            value_name = response_params[f\"{full_name}_query\"]            \n",
    "            traversals[name][\"values\"][value_name] = transform_node(data, response_params)\n",
    "    for k in traversals.keys():\n",
    "        traversals[k][\"values\"] = sort_by_relatedness_desc(traversals[k][\"values\"])\n",
    "    return list(traversals.values())\n",
    "\n",
    "def sort_by_relatedness_desc(d):\n",
    "    return {k: v for k, v in sorted(d.items(), key=lambda item: item[1][\"relatedness\"], reverse=True)}\n",
    "\n",
    "def traverse(collection, *nodes):\n",
    "    request = transform_request(*nodes)\n",
    "    response = collection.native_search(request)\n",
    "    return {\"graph\": transform_response_facet(response[\"facets\"], request[\"params\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph(traversal, query):\n",
    "    for term, data in traversal[\"graph\"][0][\"values\"][query][\"traversals\"][0][\"values\"].items():\n",
    "        print(f'{term}  {data[\"relatedness\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advil  0.70986\n",
      "motrin  0.59897\n",
      "aleve  0.4662\n",
      "ibuprofen  0.38264\n",
      "alleve  0.36649\n",
      "tylenol  0.33048\n",
      "naproxen  0.31226\n",
      "acetaminophen  0.17706\n"
     ]
    }
   ],
   "source": [
    "health_skg = get_skg(engine.get_collection(\"health\"))\n",
    "\n",
    "nodes_to_traverse = [{\"field\": \"body\", \n",
    "                      \"values\": [\"advil\"]},\n",
    "                     {\"field\": \"body\",\n",
    "                      \"min_occurrences\": 2,\n",
    "                      \"limit\": 8}]\n",
    "\n",
    "traversal = traverse(engine.get_collection(\"health\"), *nodes_to_traverse)\n",
    "print_graph(traversal, \"advil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"limit\": 0,\n",
      "  \"params\": {\n",
      "    \"q\": \"*:*\",\n",
      "    \"fore\": \"{!type=$defType v=$q}\",\n",
      "    \"back\": \"*:*\",\n",
      "    \"defType\": \"edismax\",\n",
      "    \"f0_0_query\": \"advil\"\n",
      "  },\n",
      "  \"facet\": {\n",
      "    \"f0_0\": {\n",
      "      \"type\": \"query\",\n",
      "      \"sort\": {\n",
      "        \"relatedness\": \"desc\"\n",
      "      },\n",
      "      \"facet\": {\n",
      "        \"relatedness\": {\n",
      "          \"type\": \"func\",\n",
      "          \"func\": \"relatedness($fore,$back)\"\n",
      "        },\n",
      "        \"f1_0\": {\n",
      "          \"type\": \"terms\",\n",
      "          \"limit\": 8,\n",
      "          \"sort\": {\n",
      "            \"relatedness\": \"desc\"\n",
      "          },\n",
      "          \"facet\": {\n",
      "            \"relatedness\": {\n",
      "              \"type\": \"func\",\n",
      "              \"func\": \"relatedness($fore,$back)\"\n",
      "            }\n",
      "          },\n",
      "          \"mincount\": 2,\n",
      "          \"field\": \"body\"\n",
      "        }\n",
      "      },\n",
      "      \"field\": \"body\",\n",
      "      \"query\": \"{!edismax q.op=AND qf=body v=$f0_0_query}\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "skg_search_request = health_skg.transform_request(*nodes_to_traverse)\n",
    "print(json.dumps(skg_search_request, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vibranium  0.94237\n",
      "wakandan  0.8197\n",
      "adamantium  0.80724\n",
      "wakanda  0.79122\n",
      "alloy  0.75724\n",
      "maclain  0.75623\n",
      "klaw  0.75222\n",
      "america's  0.74002\n"
     ]
    }
   ],
   "source": [
    "stackexchange_skg = get_skg(engine.get_collection(\"stackexchange\"))\n",
    "        \n",
    "query = \"vibranium\"\n",
    "nodes_to_traverse = [{\"field\": \"body\", \"values\": [query]},\n",
    "                     {\"field\": \"body\", \"min_occurrences\": 2, \"limit\": 8}]\n",
    "\n",
    "traversal = stackexchange_skg.traverse(*nodes_to_traverse)\n",
    "\n",
    "print_graph(traversal, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query:\n",
      "vibranium^5 vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 \n"
     ]
    }
   ],
   "source": [
    "expansion = \"\"\n",
    "for term, stats in traversal[\"graph\"][0][\"values\"][query] \\\n",
    "                                  [\"traversals\"][0][\"values\"].items():\n",
    "    expansion += f'{term}^{stats[\"relatedness\"]} '    \n",
    "expanded_query = f\"{query}^5 \" + expansion\n",
    "\n",
    "print(f\"Expanded Query:\\n{expanded_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Query Expansion:\n",
      "{'query': \"vibranium vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 \", 'query_fields': ['title', 'body'], 'min_match': '1'}\n",
      "\n",
      "Increased Precision, Reduced Recall Query:\n",
      "{'query': \"vibranium vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 \", 'query_fields': ['title', 'body'], 'min_match': '30%'}\n",
      "\n",
      "Increased Precision, No Reduction in Recall:\n",
      "{'query': \"vibranium AND (vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 )\", 'query_fields': ['title', 'body'], 'min_match': '2'}\n",
      "\n",
      "Slightly Increased Recall Query:\n",
      "{'query': \"vibranium vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 \", 'query_fields': ['title', 'body'], 'min_match': '2'}\n",
      "\n",
      "Same Results, Better Conceptual Ranking:\n",
      "{'query': 'vibranium', 'query_fields': ['title', 'body'], 'min_match': '2', 'query_boosts': \"vibranium^0.94237 wakandan^0.8197 adamantium^0.80724 wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002 \"}\n"
     ]
    }
   ],
   "source": [
    "def generate_request(query, min_match=None, boost=None):\n",
    "    request = {\"query\": query,\n",
    "               \"query_fields\": [\"title\", \"body\"]}\n",
    "    if min_match:\n",
    "        request[\"min_match\"] = min_match\n",
    "    if boost:        \n",
    "        request[\"query_boosts\"] = boost\n",
    "    return request\n",
    "    \n",
    "simple_expansion = generate_request(f\"{query} {expansion}\", \"1\")\n",
    "increased_conceptual_precision = generate_request(f\"{query} {expansion}\", \"30%\")\n",
    "increased_precision_same_recall = generate_request(f\"{query} AND ({expansion})\", \"2\")\n",
    "slightly_increased_recall = generate_request(f\"{query} {expansion}\", \"2\")\n",
    "same_results_better_ranking = generate_request(query, \"2\", expansion)\n",
    "\n",
    "print(f\"Simple Query Expansion:\\n{simple_expansion}\")\n",
    "print(\"\\nIncreased Precision, Reduced Recall Query:\")\n",
    "print(increased_conceptual_precision)\n",
    "print(\"\\nIncreased Precision, No Reduction in Recall:\")\n",
    "print(increased_precision_same_recall)\n",
    "print(\"\\nSlightly Increased Recall Query:\")\n",
    "print(slightly_increased_recall)\n",
    "print(\"\\nSame Results, Better Conceptual Ranking:\")\n",
    "print(same_results_better_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrases(document):\n",
    "    \"Stubbed entity extraction\"\n",
    "    return [\"this\", \"doc\", \"contains\", \"the\", \"words\", \"luke\", \n",
    "            \"magneto\", \"cyclops\", \"darth vader\", \"princess leia\", \n",
    "            \"wolverine\", \"apple\", \"banana\", \"galaxy\", \"force\", \n",
    "            \"blaster\", \"and\", \"chloe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luke  0.75212\n",
      "force  0.73248\n",
      "darth vader  0.69378\n",
      "galaxy  0.58693\n",
      "princess leia  0.50491\n",
      "blaster  0.47143\n",
      "this  0.19193\n",
      "the  0.17519\n",
      "words  0.10144\n",
      "and  0.09709\n",
      "contains  0.03434\n",
      "doc  0.00885\n",
      "chloe  0.0\n",
      "cyclops  -0.01825\n",
      "magneto  -0.02175\n",
      "banana  -0.0319\n",
      "wolverine  -0.03362\n",
      "apple  -0.03894\n"
     ]
    }
   ],
   "source": [
    "stackexchange_skg = get_skg(engine.get_collection(\"stackexchange\"))\n",
    "\n",
    "classification = \"star wars\"\n",
    "document = \"\"\"this doc contains the words luke, magneto, cyclops,\n",
    "              darth vader, princess leia, wolverine, apple, banana,\n",
    "              galaxy, force, blaster, and chloe.\"\"\"\n",
    "parsed_document = extract_phrases(document)\n",
    "nodes_to_traverse = [{\"field\": \"body\", \"values\": [classification]},\n",
    "                     {\"field\": \"body\", \"values\": parsed_document}]\n",
    "\n",
    "traversal = stackexchange_skg.traverse(*nodes_to_traverse)\n",
    "\n",
    "print_graph(traversal, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query:\n",
      "\"luke\"^0.75212 \"force\"^0.73248 \"darth vader\"^0.69378 \"galaxy\"^0.58693 \"princess leia\"^0.50491 \"blaster\"^0.47143\n"
     ]
    }
   ],
   "source": [
    "def get_scored_terms(traversal):\n",
    "    return {term: data[\"relatedness\"]\n",
    "            for term, data in traversal[\"graph\"][0][\"values\"][\"star wars\"] \\\n",
    "                                       [\"traversals\"][0][\"values\"].items()}\n",
    "\n",
    "rec_query = \" \".join(f'\"{term}\"^{score}'\n",
    "                     for term, score in get_scored_terms(traversal).items()\n",
    "                     if score > 0.25)\n",
    "\n",
    "print(f\"Expanded Query:\\n{rec_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"title\": \"At the end of Return of the Jedi, did Darth Vader learn that Princess Leia was his daughter?\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Did Luke know the &quot;Chosen One&quot; prophecy?\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Was Darth Vader at his strongest during Episode III?\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Why couldn't Snoke or Kylo Ren trace Luke using the Force?\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Does Kylo Ren know that Darth Vader reconciled with Luke?\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "stackexchange_collection = engine.get_collection(\"stackexchange\")\n",
    "\n",
    "request = {\"query\": rec_query,\n",
    "           \"query_fields\": [\"title\", \"body\"],\n",
    "           \"return_fields\": [\"title\"],\n",
    "           \"limit\": 5,\n",
    "           \"filters\": [(\"title\", \"*\")]}\n",
    "\n",
    "response = stackexchange_collection.search(**request)\n",
    "\n",
    "print(json.dumps(response[\"docs\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Arbitrary Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 5.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m relationship \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min love with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m nodes_to_traverse \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: [starting_node]},\n\u001b[1;32m      6\u001b[0m                      {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: [relationship], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_operator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOR\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      7\u001b[0m                      {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_occurrences\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m25\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}]\n\u001b[0;32m----> 9\u001b[0m traversal \u001b[38;5;241m=\u001b[39m \u001b[43mscifi_skg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnodes_to_traverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(transform_request(\u001b[38;5;241m*\u001b[39mnodes_to_traverse), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(traversal, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/engines/solr/SolrSemanticKnowledgeGraph.py:125\u001b[0m, in \u001b[0;36mSolrSemanticKnowledgeGraph.traverse\u001b[0;34m(self, *multi_nodes)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mmulti_nodes):\n\u001b[1;32m    124\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_request(\u001b[38;5;241m*\u001b[39mmulti_nodes)\n\u001b[0;32m--> 125\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m: transform_response_facet(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacets\u001b[39m\u001b[38;5;124m\"\u001b[39m], request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m])}\n",
      "File \u001b[0;32m~/engines/solr/SolrCollection.py:130\u001b[0m, in \u001b[0;36mSolrCollection.native_search\u001b[0;34m(self, request, data)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnative_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 130\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSOLR_URL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/select\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scifi_skg = get_skg(engine.get_collection(\"scifi\"))\n",
    "\n",
    "starting_node = 'jean grey'\n",
    "relationship = \"in love with\"\n",
    "nodes_to_traverse = [{\"field\": \"body\", \"values\": [starting_node]},\n",
    "                     {\"field\": \"body\", \"values\": [relationship], \"default_operator\": \"OR\"},\n",
    "                     {\"field\": \"body\", \"min_occurrences\": 25, \"limit\": 10}]\n",
    "\n",
    "traversal = scifi_skg.traverse(*nodes_to_traverse)\n",
    "print(json.dumps(transform_request(*nodes_to_traverse), indent=2))\n",
    "\n",
    "print(json.dumps(traversal, indent=2))\n",
    "print_graph(traversal, starting_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Examples (not included in chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark  0.80665\n",
      "hadoop  0.59424\n",
      "hive  0.52983\n",
      "kafka  0.51552\n",
      "impala  0.45309\n",
      "streamsets  0.39341\n",
      "scala  0.38564\n",
      "flume  0.38401\n",
      "attunity  0.37374\n",
      "mapreduce  0.36195\n"
     ]
    }
   ],
   "source": [
    "jobs_skg = get_skg(engine.get_collection(\"jobs\"))\n",
    "\n",
    "nodes_to_traverse = [{\"field\": \"job_description\", \"values\": [\"spark\"]},\n",
    "                     {\"field\": \"job_description\"}]\n",
    "\n",
    "traversal = jobs_skg.traverse(*nodes_to_traverse)\n",
    "\n",
    "print_graph(traversal, \"spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chef  0.80689\n",
      "puppet  0.59501\n",
      "ansible  0.52824\n",
      "terraform  0.3866\n",
      "jenkins  0.30455\n",
      "culinary  0.25935\n",
      "docker  0.25145\n",
      "cd  0.2434\n",
      "ci  0.23938\n",
      "ruby  0.20856\n"
     ]
    }
   ],
   "source": [
    "nodes_to_traverse = [{\"field\": \"job_description\", \"values\": [\"chef\"]},\n",
    "                     {\"field\": \"job_description\", \"min_popularity\": 0.0005}]\n",
    "\n",
    "traversal = jobs_skg.traverse(*nodes_to_traverse)\n",
    "\n",
    "print_graph(traversal, \"chef\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "You've leveraged a semantic knowledge graph to find related terms for a query, performed query expansion based upon semantically-similar terms, explored multiple different way to impact precision and recall of queries through integrating semantically-augmented queries, generated content-based recommendations leveraging a semantic knowledge graph, explored arbitrary relationship types by traversing a semantic knowledge graph.\n",
    "\n",
    "Semantic knowledge graphs can be a powerful tool for understaning user intent and interpreting both queries and content based upon meaning instead of just text kewords.\n",
    "\n",
    "Up next: Chapter 6 - [Using Context to Learn Domain-specific Language ](../ch06/1.skg-classification-disambiguation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
