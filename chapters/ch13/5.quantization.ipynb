{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy\n",
    "import math\n",
    "from aips import get_engine\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "from pyspark import SparkConf\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "engine = get_engine()\n",
    "#Recommended for making ALS run faster, if you have enough memory / cores allocated to docker\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "conf.set(\"spark.dynamicAllocation.executorMemoryOverhead\", \"8g\")\n",
    "spark = SparkSession.builder.appName(\"AIPS-ch13\").config(conf=conf).getOrCreate()\n",
    "\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=1024)\n",
    "\n",
    "#https://github.com/facebookresearch/faiss/wiki/Pre--and-post-processing\n",
    "#https://github.com/facebookresearch/faiss/wiki\n",
    "#https://huggingface.co/spaces/sentence-transformers/quantized-retrieval/blob/main/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "README.md\n",
      "concepts.pickle\n",
      "._guesses.csv\n",
      "guesses.csv\n",
      "._guesses_all.json\n",
      "guesses_all.json\n",
      "outdoors_concepts.pickle\n",
      "outdoors_embeddings.pickle\n",
      "._outdoors_golden_answers.csv\n",
      "outdoors_golden_answers.csv\n",
      "._outdoors_golden_answers.xlsx\n",
      "outdoors_golden_answers.xlsx\n",
      "._outdoors_golden_answers_20210130.csv\n",
      "outdoors_golden_answers_20210130.csv\n",
      "outdoors_labels.pickle\n",
      "outdoors_question_answering_contexts.json\n",
      "outdoors_questionanswering_test_set.json\n",
      "outdoors_questionanswering_train_set.json\n",
      "._posts.csv\n",
      "posts.csv\n",
      "predicates.pickle\n",
      "pull_aips_dependency.py\n",
      "._question-answer-seed-contexts.csv\n",
      "question-answer-seed-contexts.csv\n",
      "question-answer-squad2-guesses.csv\n",
      "._roberta-base-squad2-outdoors\n",
      "roberta-base-squad2-outdoors/\n",
      "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/._config.json\n",
      "roberta-base-squad2-outdoors/config.json\n",
      "roberta-base-squad2-outdoors/._merges.txt\n",
      "roberta-base-squad2-outdoors/merges.txt\n",
      "roberta-base-squad2-outdoors/._training_args.bin\n",
      "roberta-base-squad2-outdoors/training_args.bin\n",
      "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/._vocab.json\n",
      "roberta-base-squad2-outdoors/vocab.json\n"
     ]
    }
   ],
   "source": [
    "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
    "! cd outdoors && git pull\n",
    "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
    "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'\n",
    "\n",
    "#outdoors_collection = engine.create_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: I updated the get_embeddings method earlier in the chapter to have the same method signature, so no need to duplicate it in the manuscript. Ideally we'd load this in from a python file for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.stop_multi_process_pool(pool)\n",
    "#pool = model.start_multi_process_pool()\n",
    "#embeddings = model.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "def get_embeddings(texts, model, cache_name, ignore_cache=False):\n",
    "    cache_file_name = f\"data/embeddings/{cache_name}.pickle\"\n",
    "    if ignore_cache or not os.path.isfile(cache_file_name):        \n",
    "        embeddings = model.encode(texts, normalize_embeddings=True)\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"wb\") as fd:\n",
    "            pickle.dump(embeddings, fd)\n",
    "    else:\n",
    "        with open(cache_file_name, \"rb\") as fd:\n",
    "            embeddings = pickle.load(fd)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate code for Quantization listings\n",
    "### Generating embeddings and benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def display_results(scores, ids, data):\n",
    "    results = generate_search_results(scores, ids, data)\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "def get_outdoors_data():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    return outdoors_data\n",
    "\n",
    "def display_statistics(full_search_results, quantized_search_results, start_message=\"Recall\"):\n",
    "    index_name = quantized_search_results[\"index_name\"]\n",
    "    full_search_time = full_search_results[\"time_taken\"]\n",
    "    time_taken = quantized_search_results[\"time_taken\"]\n",
    "    time_imp = round((full_search_time - time_taken) * 100 / full_search_time, 2)\n",
    "    quantized_size = quantized_search_results[\"size\"]\n",
    "    improvement_ms = f\"({time_imp}% improvement)\"\n",
    "    improvement_size = f\"({round((full_search_results['size'] - quantized_size) * 100 / full_search_results['size'], 2)}% improvement)\"\n",
    "    print(f\"{index_name} search took: {time_taken:.3f} ms {improvement_ms}\")\n",
    "    print(f\"{index_name} index size: {round(quantized_size / 1000000, 2)} MB {improvement_size}\")\n",
    "    recall = calculate_recall(full_search_results[\"results\"], quantized_search_results[\"results\"])\n",
    "    print(f\"{start_message}: {str(round(recall, 4))}\")\n",
    "\n",
    "def calculate_recall(scored_full_results, scored_quantized_results):\n",
    "    recalls = []\n",
    "    for i in range(len(scored_full_results)):\n",
    "        full_ids = [r[\"id\"] for r in scored_full_results[i]]\n",
    "        quantized_ids = [r[\"id\"] for r in scored_quantized_results[i]]\n",
    "        recalls.append((len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "                       len(set(quantized_ids))))\n",
    "    return sum(recalls) / len(recalls)\n",
    "\n",
    "def generate_search_results(faiss_scores, faiss_ids):\n",
    "    outdoors_data = get_outdoors_data()\n",
    "    faiss_results = []\n",
    "    for i in range(len(faiss_scores)):\n",
    "        results = []\n",
    "        for j, id in enumerate(faiss_ids[i]):\n",
    "            id = int(id)\n",
    "            result = {\"score\": faiss_scores[i][j],\n",
    "                      \"title\": outdoors_data[id][\"title\"],\n",
    "                      \"body\": outdoors_data[id][\"body\"],\n",
    "                      \"id\": id}\n",
    "            results.append(result)\n",
    "        faiss_results.append(results)\n",
    "    return faiss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing full-precision embeddings using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=1024)\n",
    "\n",
    "def index_full_precision_embeddings(doc_embeddings, name):\n",
    "    index = faiss.IndexFlatIP(doc_embeddings.shape[1])\n",
    "    index.add(doc_embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def get_outdoors_embeddings(model):\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    return numpy.array(get_embeddings(post_texts, model, \"outdoors_mrl_normed\")) #TODO: This will take 2-5 hours to run the first time if not cached. Upload to github to save readers hassle.\n",
    "\n",
    "\n",
    "doc_embeddings = get_outdoors_embeddings(model) #takes 2-3 hours if not cached\n",
    "full_index = index_full_precision_embeddings(doc_embeddings, \"full_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating full-precision query embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_queries():\n",
    "    return [\"tent poles\", \"hiking trails\", \"mountain forests\",\n",
    "            \"white water\", \"best waterfalls\", \"mountain biking\",\n",
    "            \"snowboarding slopes\", \"bungee jumping\", \"public parks\"]\n",
    "\n",
    "queries = get_test_queries()\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True,\n",
    "                                normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Listing 13.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Methods for evaluating index speed, size, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_and_execute_search(index, index_name, query_embeddings, k=25):\n",
    "    start_time = time.time()\n",
    "    faiss_scores, faiss_ids = index.search(query_embeddings, k=k)\n",
    "    time_taken = ((time.time() - start_time) * 1000)\n",
    "    \n",
    "    results = {\"results\": generate_search_results(faiss_scores, faiss_ids),\n",
    "               \"time_taken\": time_taken, \n",
    "               \"faiss_scores\": faiss_scores, \"faiss_ids\": faiss_ids}\n",
    "    index_stats = {}\n",
    "    if index_name:\n",
    "        index_stats ={\"index_name\": index_name,\n",
    "                      \"size\": os.path.getsize(index_name)}\n",
    "    return results | index_stats\n",
    "\n",
    "\n",
    "def evaluate_search(full_index, quantized_index, quantized_index_name, query_embeddings, quantized_query_embeddings,\n",
    "                    k=25, display=True, log=False):\n",
    "    full_results = time_and_execute_search(full_index, \"full_embeddings\", query_embeddings, k=k)\n",
    "    quantized_results = time_and_execute_search(quantized_index, quantized_index_name,\n",
    "                                                quantized_query_embeddings, k=k)\n",
    "    if display:\n",
    "        display_statistics(full_results, quantized_results)\n",
    "    return quantized_results, full_results\n",
    "\n",
    "def evaluate_rerank_search(full_index, quantized_index, query_embeddings,\n",
    "                           quantized_embeddings, k=50, limit=25):\n",
    "    results, full_results = evaluate_search(full_index, quantized_index, None, query_embeddings,\n",
    "                                            quantized_embeddings, display=False, k=k)\n",
    "    \n",
    "    doc_embeddings = get_outdoors_embeddings(model) #This can point to a cheap on-disk data source containing the original full-precision embeddings\n",
    "    rescore_scores, rescore_ids = [], []\n",
    "    for i in range(len(results[\"results\"])):\n",
    "        embedding_ids = results[\"faiss_ids\"][i]\n",
    "        top_k_embeddings = [doc_embeddings[id] for id in embedding_ids]\n",
    "        query_embedding = query_embeddings[i]\n",
    "        scores = query_embedding @ numpy.array(top_k_embeddings).T\n",
    "        indices = scores.argsort()[::-1][:limit]\n",
    "        top_k_indices = embedding_ids[indices]\n",
    "        top_k_scores = scores[indices]\n",
    "        rescore_scores.append(top_k_scores)\n",
    "        rescore_ids.append(top_k_indices)\n",
    "\n",
    "    results = generate_search_results(rescore_scores, rescore_ids)\n",
    "    recall = calculate_recall(full_results[\"results\"], results)\n",
    "    print(f\"Reranked recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.23\n",
    "### int8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8 embeddings shape: (18456, 1024)\n",
      "int8_embeddings search took: 94.007 ms (-617.66% improvement)\n",
      "int8_embeddings index size: 18.91 MB (74.99% improvement)\n",
      "Recall: 0.9289\n",
      "Reranked recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "def index_int8_embeddings(doc_embeddings, name):\n",
    "    int8_embeddings = quantize_embeddings(doc_embeddings, precision=\"int8\")\n",
    "    print(\"Int8 embeddings shape:\", int8_embeddings.shape)\n",
    "    index = faiss.IndexScalarQuantizer(int8_embeddings.shape[1],\n",
    "                                       faiss.ScalarQuantizer.QT_8bit, )\n",
    "    index.train(int8_embeddings)\n",
    "    index.add(int8_embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "int8_index_name = \"int8_embeddings\"\n",
    "int8_index = index_int8_embeddings(doc_embeddings, int8_index_name)\n",
    "\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                                        calibration_embeddings=doc_embeddings,\n",
    "                                        precision=\"int8\")\n",
    "\n",
    "evaluate_search(full_index, int8_index, int8_index_name, query_embeddings, quantized_queries)\n",
    "evaluate_rerank_search(full_index, int8_index, query_embeddings, quantized_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.24\n",
    "### Binary Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary embeddings shape: (18456, 128)\n",
      "binary_embeddings search took: 19.520 ms (-33.95% improvement)\n",
      "binary_embeddings index size: 2.36 MB (96.87% improvement)\n",
      "Recall: 0.6044\n",
      "Reranked recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "def index_binary_embeddings(doc_embeddings, binary_index_name):\n",
    "    binary_embeddings = quantize_embeddings(doc_embeddings,\n",
    "                                    precision=\"binary\").astype(numpy.uint8)\n",
    "    print(\"Binary embeddings shape:\", binary_embeddings.shape)\n",
    "    index = faiss.IndexBinaryFlat(binary_embeddings.shape[1] * 8)\n",
    "    index.add(binary_embeddings)\n",
    "    faiss.write_index_binary(index, binary_index_name)\n",
    "    return index\n",
    "\n",
    "binary_index_name = \"binary_embeddings\"\n",
    "binary_index = index_binary_embeddings(doc_embeddings, binary_index_name)\n",
    "\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                        calibration_embeddings=doc_embeddings,\n",
    "                                       precision=\"binary\").astype(numpy.uint8)\n",
    "\n",
    "evaluate_search(full_index, binary_index, binary_index_name, query_embeddings, quantized_queries)\n",
    "evaluate_rerank_search(full_index, binary_index, query_embeddings, quantized_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.25\n",
    "### Product Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pq_embeddings search took: 29.581 ms (-24.64% improvement)\n",
      "pq_embeddings index size: 1.34 MB (98.22% improvement)\n",
      "Recall: 0.3333\n",
      "Reranked recall: 0.68\n"
     ]
    }
   ],
   "source": [
    "def index_pq_embeddings(doc_embeddings, index_name):\n",
    "    dimensions = doc_embeddings.shape[1]\n",
    "    M_subvectors = 16\n",
    "    num_bits = 8\n",
    "    index = faiss.IndexPQ(dimensions, M_subvectors, num_bits)\n",
    "    index.train(doc_embeddings)\n",
    "    index.add(doc_embeddings)   \n",
    "    faiss.write_index(index, index_name) # Commit the index to disk\n",
    "    return index\n",
    "\n",
    "pq_index_name = \"pq_embeddings\"\n",
    "pq_index = index_pq_embeddings(doc_embeddings, pq_index_name)\n",
    "\n",
    "evaluate_search(full_index, pq_index, pq_index_name, query_embeddings, query_embeddings)\n",
    "evaluate_rerank_search(full_index, pq_index, query_embeddings, query_embeddings)\n",
    "\n",
    "#TODO: consider adding IVFFlatPQ as optimization for speed to show at end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.26\n",
    "### Matryoshka Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original embeddings shape: (18456, 1024)\n",
      "\n",
      "\n",
      "mrl_embeddings_512 embeddings shape: (18456, 512)\n",
      "mrl_embeddings_512 search took: 6.998 ms (55.15% improvement)\n",
      "mrl_embeddings_512 index size: 37.8 MB (50.0% improvement)\n",
      "Recall: 0.7022\n",
      "Reranked recall: 1.0\n",
      "\n",
      "\n",
      "mrl_embeddings_256 embeddings shape: (18456, 256)\n",
      "mrl_embeddings_256 search took: 3.013 ms (75.81% improvement)\n",
      "mrl_embeddings_256 index size: 18.9 MB (75.0% improvement)\n",
      "Recall: 0.4756\n",
      "Reranked recall: 0.9688888888888888\n",
      "\n",
      "\n",
      "mrl_embeddings_128 embeddings shape: (18456, 128)\n",
      "mrl_embeddings_128 search took: 1.744 ms (84.55% improvement)\n",
      "mrl_embeddings_128 index size: 9.45 MB (87.5% improvement)\n",
      "Recall: 0.2489\n",
      "Reranked recall: 0.64\n"
     ]
    }
   ],
   "source": [
    "def index_mrl_embeddings(num_dimensions, doc_embeddings, mrl_index_name):\n",
    "    scaled_doc_embeddings = numpy.array(list(map(lambda e: e[:num_dimensions], doc_embeddings)))\n",
    "    print(f\"{mrl_index_name} embeddings shape:\", scaled_doc_embeddings.shape)\n",
    "    mrl_index = index_full_precision_embeddings(scaled_doc_embeddings, mrl_index_name) #todo: remove\n",
    "    return mrl_index\n",
    "\n",
    "print(f\"Original embeddings shape:\", doc_embeddings.shape)\n",
    "original_dimensions = doc_embeddings.shape[1] #1024\n",
    "\n",
    "for num_dimensions in [original_dimensions//2, #512\n",
    "                       original_dimensions//4, #256\n",
    "                       original_dimensions//8]: #128\n",
    "    print(\"\\n\")\n",
    "    mrl_index_name = f\"mrl_embeddings_{num_dimensions}\"\n",
    "    mrl_index = index_mrl_embeddings(num_dimensions, doc_embeddings, mrl_index_name)\n",
    "    mrl_queries = numpy.array(list(map(lambda qe: qe[:num_dimensions], query_embeddings)))\n",
    "\n",
    "    evaluate_search(full_index, mrl_index, mrl_index_name, query_embeddings, mrl_queries)\n",
    "    evaluate_rerank_search(full_index, mrl_index, query_embeddings, mrl_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.27\n",
    "### Quantization and reranking: collection/engine implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row, ArrayType, FloatType, StructField, StructType, StringType, ByteType\n",
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def calculate_outdoors_embeddingss(model):\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    doc_embeddings = get_embeddings(post_texts, model, \"outdoors_mrl_normed\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    quantized_embeddings = quantize_embeddings(doc_embeddings,\n",
    "                        calibration_embeddings=doc_embeddings,\n",
    "                                       precision=\"binary\").astype(numpy.uint8)\n",
    "    for i in range(len(outdoors_data)):\n",
    "        outdoors_data[i][\"text_embedding\"] = doc_embeddings[i].tolist()\n",
    "        print(quantized_embeddings[i].shape)\n",
    "        outdoors_data[i][\"binary_text_embedding\"] = quantized_embeddings[i].tolist()\n",
    "    return outdoors_data\n",
    "\n",
    "def build_engine_quantization_index():\n",
    "    outdoors_data = calculate_outdoors_embeddingss(model)\n",
    "    schema = StructType([StructField(\"title\", StringType()),\n",
    "                         StructField(\"body\", StringType()),\n",
    "                         StructField(\"text_embedding\", ArrayType(FloatType())),\n",
    "                         StructField(\"binary_text_embedding\", ArrayType(ByteType()))])\n",
    "    outdoors_dataframe = spark.createDataFrame(\n",
    "        [Row(title=x[\"title\"], body=x[\"body\"],\n",
    "             text_embedding=x[\"text_embedding\"],\n",
    "             binary_text_embedding=x[\"binary_text_embedding\"])\n",
    "             for x in outdoors_data], schema=schema)\n",
    "    embeddings_collection = engine.create_collection(\"outdoors_quantization\")\n",
    "    embeddings_collection.write(outdoors_dataframe)\n",
    "    return embeddings_collection\n",
    "\n",
    "def calculate_search_engine_rerank_recall(collection, full_request, binary_request):\n",
    "    full_results = collection.search(**full_request)[\"docs\"]\n",
    "    binary_results = collection.search(**binary_request)[\"docs\"]\n",
    "    full_ids = [r[\"id\"] for r in full_results]\n",
    "    quantized_ids = [r[\"id\"] for r in binary_results]\n",
    "    recall = (len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "              len(set(quantized_ids)))\n",
    "    return recall\n",
    "\n",
    "def search_request(query_vector, query_field,\n",
    "                   rerank_vector=None, rerank_query_field=None,\n",
    "                   quantization_type=None, k=1000, limit=25):\n",
    "    request = {\"query\": query_vector,\n",
    "               \"query_fields\": [query_field],\n",
    "               \"return_fields\": [\"title\", \"body\", \"id\",\"score\"],\n",
    "               \"limit\": limit,\n",
    "               \"k\": k,\n",
    "               \"quantization_type\": quantization_type,}\n",
    "    if rerank_vector is not None and rerank_query_field:\n",
    "        request[\"rerank_query\"] = {\"query\": rerank_vector,\n",
    "                                   \"query_fields\": [rerank_query_field],\n",
    "                                   \"k\": k}\n",
    "    return request\n",
    "\n",
    "collection = build_engine_quantization_index()\n",
    "\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                        calibration_embeddings=doc_embeddings,\n",
    "                                        precision=\"binary\")\n",
    "total_recall = 0\n",
    "for i, query in enumerate(query_embeddings):\n",
    "    full_request = search_request(query.tolist(), \"text_embedding\")\n",
    "    binary_request = search_request(query_vector=quantized_queries[i].tolist(),\n",
    "                                    query_field=\"binary_text_embedding\",\n",
    "                                    rerank_vector=query.tolist(),\n",
    "                                    rerank_query_field=\"text_embedding\",\n",
    "                                    quantization_type=\"BINARY\", limit=250)\n",
    "    total_recall += calculate_search_engine_rerank_recall(\n",
    "                  collection, full_request, binary_request)\n",
    "\n",
    "print(f\"Search engine rerank recall: {total_recall / len(query_embeddings)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
