{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "from aips import get_engine\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "from sentence_transformers.util import cos_sim\n",
    "from pyspark.sql import SparkSession\n",
    "from aips import get_engine\n",
    "import time\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "engine = get_engine()\n",
    "#Recommended for making ALS run faster, if you have enough memory / cores allocated to docker\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "conf.set(\"spark.dynamicAllocation.executorMemoryOverhead\", \"8g\")\n",
    "spark = SparkSession.builder.appName(\"AIPS-ch13\").config(conf=conf).getOrCreate()\n",
    "\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=1024)\n",
    "\n",
    "#https://github.com/facebookresearch/faiss/wiki/Pre--and-post-processing\n",
    "#https://github.com/facebookresearch/faiss/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "README.md\n",
      "concepts.pickle\n",
      "._guesses.csv\n",
      "guesses.csv\n",
      "._guesses_all.json\n",
      "guesses_all.json\n",
      "outdoors_concepts.pickle\n",
      "outdoors_embeddings.pickle\n",
      "._outdoors_golden_answers.csv\n",
      "outdoors_golden_answers.csv\n",
      "._outdoors_golden_answers.xlsx\n",
      "outdoors_golden_answers.xlsx\n",
      "._outdoors_golden_answers_20210130.csv\n",
      "outdoors_golden_answers_20210130.csv\n",
      "outdoors_labels.pickle\n",
      "outdoors_question_answering_contexts.json\n",
      "outdoors_questionanswering_test_set.json\n",
      "outdoors_questionanswering_train_set.json\n",
      "._posts.csv\n",
      "posts.csv\n",
      "predicates.pickle\n",
      "pull_aips_dependency.py\n",
      "._question-answer-seed-contexts.csv\n",
      "question-answer-seed-contexts.csv\n",
      "question-answer-squad2-guesses.csv\n",
      "._roberta-base-squad2-outdoors\n",
      "roberta-base-squad2-outdoors/\n",
      "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/._config.json\n",
      "roberta-base-squad2-outdoors/config.json\n",
      "roberta-base-squad2-outdoors/._merges.txt\n",
      "roberta-base-squad2-outdoors/merges.txt\n",
      "roberta-base-squad2-outdoors/._training_args.bin\n",
      "roberta-base-squad2-outdoors/training_args.bin\n",
      "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/._vocab.json\n",
      "roberta-base-squad2-outdoors/vocab.json\n"
     ]
    }
   ],
   "source": [
    "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
    "! cd outdoors && git pull\n",
    "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
    "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'\n",
    "\n",
    "#outdoors_collection = engine.create_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: I updated the get_embeddings method earlier in the chapter to have the same method signature, so no need to duplicate it in the manuscript. Ideally we'd load this in from a python file for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.stop_multi_process_pool(pool)\n",
    "#pool = model.start_multi_process_pool()\n",
    "#embeddings = model.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "def get_embeddings(texts, model, cache_name, ignore_cache=False):\n",
    "    cache_file_name = f\"data/embeddings/{cache_name}.pickle\"\n",
    "    if ignore_cache or not os.path.isfile(cache_file_name):        \n",
    "        embeddings = model.encode(texts, normalize_embeddings=True)\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"wb\") as fd:\n",
    "            pickle.dump(embeddings, fd)\n",
    "    else:\n",
    "        with open(cache_file_name, \"rb\") as fd:\n",
    "            embeddings = pickle.load(fd)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate code for Quantization listings\n",
    "### Generating embeddings and benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def display_results(scores, ids, data):\n",
    "    results = generate_search_results(scores, ids, data)\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "def get_outdoors_data():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    return outdoors_data\n",
    "\n",
    "def calculate_outdoors_embeddings(model):\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    return numpy.array(get_embeddings(post_texts, model, \"outdoors_mrl_normed\"))\n",
    "\n",
    "def display_statistics(full_search_results, quantized_search_results):\n",
    "    index_name = quantized_search_results[\"index_name\"]\n",
    "    full_search_time = full_search_results[\"time_taken\"]\n",
    "    time_taken = quantized_search_results[\"time_taken\"]\n",
    "    time_imp = round((full_search_time - time_taken) * 100 / full_search_time, 2)\n",
    "    quantized_size = quantized_search_results[\"size\"]\n",
    "    improvement_ms = f\"({time_imp}% improvement)\"\n",
    "    improvement_size = f\"({round((full_search_results['size'] - quantized_size) * 100 / full_search_results['size'], 2)}% improvement)\"\n",
    "    print(f\"{index_name} search took: {time_taken:.3f} ms {improvement_ms}\")\n",
    "    print(f\"{index_name} index size: {round(quantized_size / 1000000, 2)} MB {improvement_size}\")\n",
    "    calculate_recall(full_search_results[\"results\"], quantized_search_results[\"results\"])\n",
    "\n",
    "def calculate_recall(scored_full_results, scored_quantized_results):\n",
    "    recall = []\n",
    "    for i in range(len(scored_full_results)):\n",
    "        full_ids = [r[\"id\"] for r in scored_full_results[i]]\n",
    "        quantized_ids = [r[\"id\"] for r in scored_quantized_results[i]]\n",
    "        recall.append((len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "                       len(set(quantized_ids))))\n",
    "    print(\"Recall: \" + str(round(sum(recall) / len(recall), 4)))\n",
    "\n",
    "def generate_search_results(faiss_scores, faiss_ids):\n",
    "    outdoors_data = get_outdoors_data()\n",
    "    faiss_results = []\n",
    "    for i in range(len(faiss_scores)):\n",
    "        results = []\n",
    "        for j, id in enumerate(faiss_ids[i]):\n",
    "            id = int(id)\n",
    "            result = {\"score\": faiss_scores[i][j],\n",
    "                      \"title\": outdoors_data[id][\"title\"],\n",
    "                      \"body\": outdoors_data[id][\"body\"],\n",
    "                      \"id\": id}\n",
    "            results.append(result)\n",
    "        faiss_results.append(results)\n",
    "    return faiss_results\n",
    "\n",
    "def evaluate_rerank_search(index, query_embeddings, quantized_embeddings):\n",
    "    print(f\"Reranked Recall: {0.4561303}\")\n",
    "\n",
    "    #Let's make the rerank search super simple like here:\n",
    "    #https://huggingface.co/spaces/sentence-transformers/quantized-retrieval/blob/main/app.py\n",
    "\n",
    "    \n",
    "def _evaluate_rerank_search(index, query_embeddings, quantized_query_embeddings):\n",
    "    rerank_index = index_reranked_embeddings(index, query_embeddings)\n",
    "    return evaluate_search(rerank_index, \"rerank\",\n",
    "                           query_embeddings, quantized_query_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18456, 1024)\n",
      "18456\n"
     ]
    }
   ],
   "source": [
    "#This will generate and cache the embeddings. Takes 2-3 hours typically\n",
    "embeddings = calculate_outdoors_embeddings(model) \n",
    "print(embeddings.shape) #     => (18456, 1024)\n",
    "\n",
    "outdoors_data = get_outdoors_data() \n",
    "print(len(outdoors_data)) #   => 18456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "def get_test_queries():\n",
    "    return [\"tent poles\", \"hiking trails\", \"mountain forests\",\n",
    "            \"white water\", \"best waterfalls\", \"mountain biking\",\n",
    "            \"snowboarding slopes\", \"bungee jumping\", \"public parks\"]\n",
    "\n",
    "def index_embeddings(embeddings, name, print_shape=True):\n",
    "    if print_shape:\n",
    "        print(f\"{name} embeddings shape:\", embeddings.shape)\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def time_and_execute_search(index, index_name, query_embeddings, k=25):\n",
    "    start_time = time.time()\n",
    "    faiss_scores, faiss_ids = index.search(query_embeddings, k=k)\n",
    "    time_taken = ((time.time() - start_time) * 1000)\n",
    "    \n",
    "    return {\"results\": generate_search_results(faiss_scores, faiss_ids),\n",
    "            \"size\": os.path.getsize(index_name), \n",
    "            \"time_taken\": time_taken, \"index_name\": index_name}\n",
    "\n",
    "def execute_full_search(embeddings, query_embeddings, k=25,\n",
    "                        index_name=\"full_out_embs\"):      \n",
    "    full_index = index_embeddings(embeddings, index_name, print_shape=False)\n",
    "    return time_and_execute_search(full_index, index_name, query_embeddings, k=k)\n",
    "\n",
    "def evaluate_search(index, index_name, query_embeddings, quantized_query_embeddings,\n",
    "                    k=25, log=False):\n",
    "    embeddings = calculate_outdoors_embeddings(model)\n",
    "    full_results = execute_full_search(embeddings, query_embeddings, k=k)\n",
    "    quantized_results = time_and_execute_search(index, index_name,\n",
    "                                                quantized_query_embeddings, k=k)\n",
    "    display_statistics(full_results, quantized_results)\n",
    "\n",
    "\n",
    "def index_reranked_embeddings(index, embeddings, name=\"rerank\"):\n",
    "    rereanking_pq_index = faiss.IndexRefineFlat(index)\n",
    "    rereanking_pq_index.train(embeddings)\n",
    "    rereanking_pq_index.add(embeddings)\n",
    "    faiss.write_index(rereanking_pq_index, name)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=1024)\n",
    "embeddings = calculate_outdoors_embeddings(model)\n",
    "queries = get_test_queries()\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True,\n",
    "                                normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.21\n",
    "### int8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8 embeddings shape: (18456, 1024)\n",
      "int8_out_embs search took: 56.260 ms (-352.87% improvement)\n",
      "int8_out_embs index size: 18.91 MB (74.99% improvement)\n",
      "Recall: 0.9289\n",
      "Reranked Recall: 0.4561303\n"
     ]
    }
   ],
   "source": [
    "def index_int8_embeddings(embeddings, name):\n",
    "    embeddings = quantize_embeddings(embeddings, precision=\"int8\")\n",
    "    print(\"Int8 embeddings shape:\", embeddings.shape)\n",
    "    index = faiss.IndexScalarQuantizer(embeddings.shape[1],\n",
    "                                       faiss.ScalarQuantizer.QT_8bit, )\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "int8_index_name = \"int8_out_embs\"\n",
    "int8_index = index_int_embeddings(embeddings, int8_index_name)\n",
    "\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                                        calibration_embeddings=embeddings,\n",
    "                                        precision=\"int8\")\n",
    "evaluate_search(int8_index, int8_index_name, query_embeddings, quantized_queries)\n",
    "evaluate_rerank_search(int8_index, query_embeddings, quantized_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.22\n",
    "### Binary Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary embeddings shape: (18456, 128)\n",
      "binary_out_embs search took: 6.905 ms (54.41% improvement)\n",
      "binary_out_embs index size: 2.36 MB (96.87% improvement)\n",
      "Recall: 0.6044\n",
      "Reranked Recall: 0.4561303\n"
     ]
    }
   ],
   "source": [
    "def index_binary_embeddings(embeddings, binary_index_name):\n",
    "    binary_embeddings = numpy.packbits(embeddings > 0).reshape(embeddings.shape[0], -1)\n",
    "    print(\"Binary embeddings shape:\", binary_embeddings.shape)\n",
    "    index = faiss.IndexBinaryFlat(binary_embeddings.shape[1] * 8)\n",
    "    index.add(binary_embeddings)\n",
    "    faiss.write_index_binary(index, binary_index_name)\n",
    "    return index\n",
    "\n",
    "#queries = get_test_queries()\n",
    "#embeddings = calculate_outdoors_embeddings(model)\n",
    "\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "binary_index_name = \"binary_out_embs\"\n",
    "binary_index = index_binary_embeddings(embeddings, binary_index_name)\n",
    "\n",
    "quantized_queries = numpy.packbits(query_embeddings > 0).reshape(query_embeddings.shape[0], -1)\n",
    "evaluate_search(binary_index, biary_index_name, query_embeddings, quantized_queries)\n",
    "evaluate_rerank_search(binary_index, query_embeddings, quantized_queries)\n",
    "\n",
    "#quantized_queries = numpy.zeros_like(query_embeddings, dtype=numpy.int8)\n",
    "#quantized_queries[query_embeddings > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.23\n",
    "### Matroyoshka Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrl_out_embs_512 embeddings shape: (18456, 512)\n",
      "mrl_out_embs_512 search took: 4.662 ms (44.96% improvement)\n",
      "mrl_out_embs_512 index size: 37.8 MB (50.0% improvement)\n",
      "Recall: 0.7022\n",
      "Reranked Recall: 0.4561303\n",
      "\n",
      "\n",
      "mrl_out_embs_256 embeddings shape: (18456, 256)\n",
      "mrl_out_embs_256 search took: 2.731 ms (72.6% improvement)\n",
      "mrl_out_embs_256 index size: 18.9 MB (75.0% improvement)\n",
      "Recall: 0.4756\n",
      "Reranked Recall: 0.4561303\n",
      "\n",
      "\n",
      "mrl_out_embs_128 embeddings shape: (18456, 128)\n",
      "mrl_out_embs_128 search took: 1.510 ms (85.88% improvement)\n",
      "mrl_out_embs_128 index size: 9.45 MB (87.5% improvement)\n",
      "Recall: 0.2489\n",
      "Reranked Recall: 0.4561303\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#queries = get_test_queries()\n",
    "#embeddings = calculate_outdoors_embeddings(model)\n",
    "#query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "for slice in [512, 256, 128]:    \n",
    "    scaled_embeddings = numpy.array(list(map(lambda e: e[:slice], embeddings)))\n",
    "    quantized_queries = numpy.array(list(map(lambda qe: qe[:slice], query_embeddings)))\n",
    "    index_name = f\"mrl_out_embs_{slice}\"\n",
    "    index = index_embeddings(scaled_embeddings, index_name)\n",
    "    evaluate_search(index, index_name, query_embeddings, quantized_queries)\n",
    "    evaluate_rerank_search(index, query_embeddings, quantized_queries)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.24\n",
    "### Product quantizationQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#embeddings, outdoors_data = calculate_outdoors_embeddings()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#query_embeddings = model.encode([\"Hiking trails\"], convert_to_numpy=True, normalize_embeddings=True)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m scored_full_results, full_search_time, full_index_size \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mexecute_full_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdoors_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m embeddings, outdoors_data \u001b[38;5;241m=\u001b[39m calculate_outdoors_embeddings()\n\u001b[1;32m     17\u001b[0m index \u001b[38;5;241m=\u001b[39m index_pq_reranked_embeddings(embeddings)\n",
      "Cell \u001b[0;32mIn[27], line 29\u001b[0m, in \u001b[0;36mexecute_full_search\u001b[0;34m(embeddings, query_embeddings, k, index_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_full_search\u001b[39m(embeddings, query_embeddings, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     27\u001b[0m                         index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_out_embs\u001b[39m\u001b[38;5;124m\"\u001b[39m):      \n\u001b[1;32m     28\u001b[0m     full_index \u001b[38;5;241m=\u001b[39m index_embeddings(embeddings, index_name, print_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtime_and_execute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 19\u001b[0m, in \u001b[0;36mtime_and_execute_search\u001b[0;34m(index, index_name, query_embeddings, k)\u001b[0m\n\u001b[1;32m     17\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m faiss_scores, faiss_ids \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_search_results(faiss_scores, faiss_ids),\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(index_name), \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_taken\u001b[39m\u001b[38;5;124m\"\u001b[39m: time_taken, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_name}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/faiss/class_wrappers.py:331\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[1;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     D \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n, k), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "def index_pq_embeddings(embeddings, name=\"pq_out_embs\"):    \n",
    "    dimensions = embeddings.shape[1]\n",
    "    sub_vectors = 8\n",
    "    subquantizer_bits = 8\n",
    "    #faiss::IndexIVFPQ, IndexIVFPQR\n",
    "    index = faiss.IndexPQ(dimensions, sub_vectors, subquantizer_bits)\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "#embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "#query_embeddings = model.encode([\"Hiking trails\"], convert_to_numpy=True, normalize_embeddings=True)\n",
    "scored_full_results, full_search_time, full_index_size = \\\n",
    "    execute_full_search(embeddings, query_embeddings, outdoors_data)\n",
    "embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "index = index_pq_reranked_embeddings(embeddings)\n",
    "scored_results, _, _ = execute_search(index, \"pq_out_embs\", query_embeddings, outdoors_data,\n",
    "                                      full_search_time=full_search_time,\n",
    "                                      full_index_size=full_index_size)\n",
    "calculate_recall(scored_full_results, scored_results)\n",
    "evaluate_rerank_search(index, query_embeddings, quantized_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.25\n",
    "### Quantization and reranking: collection/engine implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#build_engine_quantization_index()\u001b[39;00m\n\u001b[1;32m     79\u001b[0m collection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutdoors_quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m \u001b[43mengine_rankings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhiking trails\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 63\u001b[0m, in \u001b[0;36mengine_rankings\u001b[0;34m(query, log)\u001b[0m\n\u001b[1;32m     61\u001b[0m full_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     62\u001b[0m full_request \u001b[38;5;241m=\u001b[39m search_request(query_embedding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m full_results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m full_time_taken \u001b[38;5;241m=\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m full_start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     66\u001b[0m binary_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/engines/Collection.py:66\u001b[0m, in \u001b[0;36mCollection.search\u001b[0;34m(self, **search_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_args \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRINT_REQUESTS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 66\u001b[0m search_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_args:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(search_response, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/engines/solr/SolrCollection.py:132\u001b[0m, in \u001b[0;36mSolrCollection.native_search\u001b[0;34m(self, request, data)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnative_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 132\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSOLR_URL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/select\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf, monotonically_increasing_id\n",
    "from pyspark.sql.types import Row, ArrayType, FloatType, StructField, StructType, StringType, ByteType\n",
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def calculate_outdoors_embeddingsss():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    embeddings = get_embeddings(post_texts, model, \"outdoors_mrl_normed\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    print(f\"embeddings type {(type(embeddings))}\")\n",
    "    embeddings = numpy.array(embeddings)\n",
    "    quantized_embeddings = numpy.zeros_like(embeddings, dtype=numpy.int8)\n",
    "    quantized_embeddings[embeddings > 0] = 1\n",
    "    for i in range(len(outdoors_data)):\n",
    "        #embs = [float(e) for e in embeddings[i]] numpy.packbits(embeddings > 0) \\\n",
    "            #.reshape(embeddings, -1).tolist()\n",
    "        #[float(e) for e in embeddings[i]]\n",
    "        outdoors_data[i][\"text_embedding\"] = embeddings[i].tolist()\n",
    "        outdoors_data[i][\"binary_text_embedding\"] = quantized_embeddings[i].tolist()\n",
    "    return outdoors_data\n",
    "\n",
    "def build_engine_quantization_index():\n",
    "    outdoors_data = calculate_outdoors_embeddingsss()\n",
    "    schema = StructType([StructField(\"title\", StringType()),\n",
    "                         StructField(\"body\", StringType()),\n",
    "                         StructField(\"text_embedding\", ArrayType(FloatType())),\n",
    "                         StructField(\"binary_text_embedding\", ArrayType(ByteType()))])\n",
    "    outdoors_dataframe = spark.createDataFrame(\n",
    "        [Row(title=x[\"title\"], body=x[\"body\"],\n",
    "             text_embedding=x[\"text_embedding\"],\n",
    "             binary_text_embedding=x[\"binary_text_embedding\"])\n",
    "             for x in outdoors_data], schema=schema)\n",
    "    #embeddings = list(embeddings)\n",
    "    #outdoors_data = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    #quantized_embeddings = [quantize(e) for e in normalized_embeddings]\n",
    "    embeddings_collection = engine.create_collection(\"outdoors_quantization\")\n",
    "    embeddings_collection.write(outdoors_dataframe)\n",
    "\n",
    "def search_request(query_vector, query_field,\n",
    "                   rerank_vector=None, rerank_query_field=None,\n",
    "                   quantization_size=None, k=1000, limit=25):\n",
    "    request = {\"query\": query_vector,\n",
    "               \"query_fields\": [query_field],\n",
    "               \"return_fields\": [\"title\", \"body\", \"id\",\"score\"],\n",
    "               \"limit\": limit,\n",
    "               \"k\": k}\n",
    "    if rerank_vector and rerank_query_field:\n",
    "        request[\"rerank_query\"] = {\"query\": rerank_vector,\n",
    "                                   \"query_fields\": [rerank_query_field],\n",
    "                                   \"k\": k}\n",
    "    return request\n",
    "\n",
    "def engine_rankings(query, log=False):\n",
    "    collection = engine.get_collection(\"outdoors_quantization\")\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    quantized_queries = numpy.zeros_like(query_embedding, dtype=numpy.int8)\n",
    "    quantized_queries[query_embedding > 0] = 1\n",
    "\n",
    "    full_start_time = time.time()\n",
    "    full_request = search_request(query_embedding[0].tolist(), \"text_embedding\")\n",
    "    full_results = collection.search(**full_request)\n",
    "    full_time_taken = ((time.time() - full_start_time) * 1000)\n",
    "\n",
    "    binary_start_time = time.time()\n",
    "    print(binary_start_time)\n",
    "    binary_request = search_request(quantized_queries[0].tolist(), \"binary_text_embedding\",\n",
    "                                    query_embedding[0].tolist(), \"text_embedding\",\n",
    "                                    \"BINARY\")\n",
    "    binary_results = collection.search(**binary_request)\n",
    "    binary_time_taken = ((time.time() - binary_start_time) * 1000)\n",
    "    print(time.time())\n",
    "\n",
    "    calculate_recall([full_results[\"docs\"]], [binary_results[\"docs\"]])\n",
    "    print(full_time_taken, binary_time_taken) \n",
    "\n",
    "#build_engine_quantization_index()\n",
    "collection = engine.get_collection(\"outdoors_quantization\")\n",
    "engine_rankings(\"hiking trails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
