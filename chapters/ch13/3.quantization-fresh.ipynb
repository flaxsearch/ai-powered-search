{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "from aips import get_engine\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "from sentence_transformers.util import cos_sim\n",
    "from pyspark.sql import SparkSession\n",
    "from aips import get_engine\n",
    "import time\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "engine = get_engine()\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'outdoors'...\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 25 (delta 0), reused 22 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (25/25), 491.39 MiB | 8.83 MiB/s, done.\n",
      "Already up to date.\n",
      "README.md\n",
      "concepts.pickle\n",
      "._guesses.csv\n",
      "guesses.csv\n",
      "._guesses_all.json\n",
      "guesses_all.json\n",
      "outdoors_concepts.pickle\n",
      "outdoors_embeddings.pickle\n",
      "._outdoors_golden_answers.csv\n",
      "outdoors_golden_answers.csv\n",
      "._outdoors_golden_answers.xlsx\n",
      "outdoors_golden_answers.xlsx\n",
      "._outdoors_golden_answers_20210130.csv\n",
      "outdoors_golden_answers_20210130.csv\n",
      "outdoors_labels.pickle\n",
      "outdoors_question_answering_contexts.json\n",
      "outdoors_questionanswering_test_set.json\n",
      "outdoors_questionanswering_train_set.json\n",
      "._posts.csv\n",
      "posts.csv\n",
      "predicates.pickle\n",
      "pull_aips_dependency.py\n",
      "._question-answer-seed-contexts.csv\n",
      "question-answer-seed-contexts.csv\n",
      "question-answer-squad2-guesses.csv\n",
      "._roberta-base-squad2-outdoors\n",
      "roberta-base-squad2-outdoors/\n",
      "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/._config.json\n",
      "roberta-base-squad2-outdoors/config.json\n",
      "roberta-base-squad2-outdoors/._merges.txt\n",
      "roberta-base-squad2-outdoors/merges.txt\n",
      "roberta-base-squad2-outdoors/._training_args.bin\n",
      "roberta-base-squad2-outdoors/training_args.bin\n",
      "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/._vocab.json\n",
      "roberta-base-squad2-outdoors/vocab.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
    "! cd outdoors && git pull\n",
    "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
    "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'\n",
    "\n",
    "#outdoors_collection = engine.create_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f4077be0854e99a83e07678562394f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3971d2af697547979c8da08d604836bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a73ae23f394a3b9655a185339ffbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/114k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a42931071fe4d3fa1fcebe74f52bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3596271a12a149569c3558eae82c1dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19b39619c1a4f25beb40d36b9e8e0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf3bd2e15b54bd785c003dde4ec9245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b5e7de2e1246739149fb356f240ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308d39846a8f435a9a33b04afb45e882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfba389850b42988a578284dee8e9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9ca57c8d2542e9a1b82a899cf2f826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dimensions = 1024\n",
    "#model = SentenceTransformer(\"tomaarsen/mpnet-base-nli-matryoshka\", matryoshka_dims=64)\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=dimensions)\n",
    "#_ = model.half()\n",
    "def get_embeddings(texts, cache_name, ignore_cache=False):\n",
    "    cache_file_name = f\"data/embeddings/{cache_name}.pickle\"\n",
    "    if ignore_cache or not os.path.isfile(cache_file_name):        \n",
    "        #pool = model.start_multi_process_pool()\n",
    "        embeddings = model.encode(texts, normalize_embeddings=True)\n",
    "        #model.stop_multi_process_pool(pool)\n",
    "        #embeddings = model.encode(texts, convert_to_tensor=False).tolist()\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"wb\") as fd:\n",
    "            pickle.dump(embeddings, fd)\n",
    "    else:\n",
    "        with open(cache_file_name, \"rb\") as fd:\n",
    "            embeddings = pickle.load(fd)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.21\n",
    "### Generating embeddings and benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datasets import load_dataset\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def calculate_outdoors_embeddings():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    embeddings = get_embeddings(post_texts, \"outdoors_mrl_normed\")\n",
    "    return numpy.array(embeddings), outdoors_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoors_data = calculate_outdoors_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(outdoors_data[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.22\n",
    "### int8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.quantization:Computing int8 quantization buckets based on 1 embedding. int8 quantization is more stable with `ranges` calculated from more embeddings or a `calibration_embeddings` that can be used to calculate the buckets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_out_embs search took: 0.005 sec\n",
      "full_out_embs index size: 75595821 bytes\n",
      "int8_out_embs search took: 0.005 sec\n",
      "int8_out_embs index size: 75595821 bytes\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/quantization.py:426: RuntimeWarning: invalid value encountered in divide\n",
      "  return ((embeddings - starts) / steps - 128).astype(np.int8)\n"
     ]
    }
   ],
   "source": [
    "def execute_search(index, index_name, embedded_query, k=25):\n",
    "    start_time = time.time()\n",
    "    faiss_scores, faiss_doc_ids = index.search(embedded_query, k)\n",
    "    print(f\"{index_name} search took: {(time.time() - start_time):.3f} sec\")\n",
    "    print(f\"{index_name} index size: {os.path.getsize(index_name)} bytes\")\n",
    "    return faiss_scores, faiss_doc_ids\n",
    "\n",
    "def index_embeddings(embeddings, name):\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def display_results(scores, ids, data):\n",
    "    results = apply_scores(scores, ids, data)\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "def apply_scores(scores, ids, data):\n",
    "    scores = list(list(scores)[0])\n",
    "    ids = list(ids)\n",
    "    results = []\n",
    "    for i, id in enumerate(ids[0]):\n",
    "        id = int(id)\n",
    "        result = {\"score\": scores[i],\n",
    "                  \"title\": data[id][\"title\"],\n",
    "                  \"body\": data[id][\"body\"],\n",
    "                  \"id\": id}\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def calculate_recall(scored_full_results, scored_quantized_results):\n",
    "    full_ids = [r[\"id\"] for r in scored_full_results]\n",
    "    quantized_ids = [r[\"id\"] for r in scored_quantized_results]\n",
    "    recall =  (len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "                len(set(quantized_ids)))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "\n",
    "embeddings, dataframe = calculate_outdoors_embeddings()\n",
    "outdoors_data = list(dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "full_index = index_embeddings(embeddings, \"full_out_embs\")\n",
    "query_embeddings = model.encode([\"tent poles\"], convert_to_numpy=True, normalize_embeddings=True)\n",
    "full_search_scores, ids = execute_search(full_index, \"full_out_embs\", query_embeddings)\n",
    "scored_full_results = apply_scores(full_search_scores, ids, outdoors_data)\n",
    "\n",
    "int8_embeddings = quantize_embeddings(embeddings, precision=\"int8\")\n",
    "int8_index = index_embeddings(int8_embeddings, \"int8_out_embs\")\n",
    "int8_query_embeddings = quantize_embeddings(query_embeddings, precision=\"int8\")\n",
    "int8_search_scores, int8_ids = execute_search(int8_index, \"int8_out_embs\", int8_query_embeddings)\n",
    "scored_int8_results = apply_scores(int8_search_scores, int8_ids, outdoors_data)\n",
    "\n",
    "calculate_recall(scored_full_results, scored_int8_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.23\n",
    "### Binary Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 128 into shape (1024,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     faiss\u001b[38;5;241m.\u001b[39mwrite_index_binary(binary_embeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_out_embs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[0;32m---> 11\u001b[0m binary_index \u001b[38;5;241m=\u001b[39m \u001b[43mindex_binary_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m binary_query_embeddings \u001b[38;5;241m=\u001b[39m binary_quantize_embeddings(query_embeddings)\n\u001b[1;32m     13\u001b[0m binary_search_scores, binary_ids \u001b[38;5;241m=\u001b[39m execute_search(binary_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_out_embs\u001b[39m\u001b[38;5;124m\"\u001b[39m, binary_query_embeddings)\n",
      "Cell \u001b[0;32mIn[89], line 5\u001b[0m, in \u001b[0;36mindex_binary_embeddings\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_binary_embeddings\u001b[39m(embeddings):\n\u001b[0;32m----> 5\u001b[0m     binary_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_quantize_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexBinaryFlat(binary_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      7\u001b[0m     index\u001b[38;5;241m.\u001b[39madd(binary_embeddings)\n",
      "Cell \u001b[0;32mIn[89], line 2\u001b[0m, in \u001b[0;36mbinary_quantize_embeddings\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_quantize_embeddings\u001b[39m(embeddings):    \n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpackbits\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 128 into shape (1024,newaxis)"
     ]
    }
   ],
   "source": [
    "def binary_quantize_embeddings(embeddings):    \n",
    "    return numpy.packbits(embeddings > 0).reshape(embeddings.shape[0], -1)\n",
    "\n",
    "def index_binary_embeddings(embeddings):\n",
    "    binary_embeddings = binary_quantize_embeddings(list(embeddings))\n",
    "    index = faiss.IndexBinaryFlat(binary_embeddings.shape[1])\n",
    "    index.add(binary_embeddings)\n",
    "    faiss.write_index_binary(binary_embeddings, \"binary_out_embs\")\n",
    "    return index\n",
    "\n",
    "binary_index = index_binary_embeddings(embeddings)\n",
    "binary_query_embeddings = binary_quantize_embeddings(query_embeddings)\n",
    "binary_search_scores, binary_ids = execute_search(binary_index, \"binary_out_embs\", binary_query_embeddings)\n",
    "scored_bintary_results = apply_scores(binary_search_scores, binary_ids, outdoors_data)\n",
    "\n",
    "calculate_recall(scored_full_results, scored_int8_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.24\n",
    "### Matroyoshka Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mrl_quantized_searches(embeddings, queries):\n",
    "    query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    for slice in [512, 256, 128]:\n",
    "        scaled_embeddings = map(lambda e: e[:slice], embeddings)\n",
    "        index = index_embeddings(scaled_embeddings)\n",
    "        scaled_query_embeddings = map(lambda qe: qe[:slice], query_embeddings)\n",
    "        yield evaluate_search(index, scaled_query_embeddings)\n",
    "\n",
    "queries = get_evaluation_queries()\n",
    "embeddings = calculate_outdoors_embeddings()\n",
    "evaluations = evaluate_mrl_quantized_searches(embeddings, queries)\n",
    "display(*evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.25\n",
    "### Product quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_pq_embeddings(embeddings):    \n",
    "    dimensions = embeddings.shape[1]\n",
    "    sub_vectors = 8\n",
    "    subquantizer_bits = 8\n",
    "    index = faiss.IndexPQ(dimensions, sub_vectors, subquantizer_bits)\n",
    "    index.train(embeddings)\n",
    "    return index\n",
    "\n",
    "embeddings = calculate_outdoors_embeddings()\n",
    "index = index_pq_embeddings()\n",
    "queries = get_evaluation_queries()\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "evaluation = evaluate_search(index, query_embeddings)\n",
    "display(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
