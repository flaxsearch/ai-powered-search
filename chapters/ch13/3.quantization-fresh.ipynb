{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "from aips import get_engine\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "from sentence_transformers.util import cos_sim\n",
    "from pyspark.sql import SparkSession\n",
    "from aips import get_engine\n",
    "import time\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "engine = get_engine()\n",
    "#Recommended for making ALS run faster, if you have enough memory / cores allocated to docker\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "conf.set(\"spark.dynamicAllocation.executorMemoryOverhead\", \"8g\")\n",
    "spark = SparkSession.builder.appName(\"AIPS-ch13\").config(conf=conf).getOrCreate()\n",
    "\n",
    "#https://github.com/facebookresearch/faiss/wiki/Pre--and-post-processing\n",
    "#https://github.com/facebookresearch/faiss/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "README.md\n",
      "concepts.pickle\n",
      "._guesses.csv\n",
      "guesses.csv\n",
      "._guesses_all.json\n",
      "guesses_all.json\n",
      "outdoors_concepts.pickle\n",
      "outdoors_embeddings.pickle\n",
      "._outdoors_golden_answers.csv\n",
      "outdoors_golden_answers.csv\n",
      "._outdoors_golden_answers.xlsx\n",
      "outdoors_golden_answers.xlsx\n",
      "._outdoors_golden_answers_20210130.csv\n",
      "outdoors_golden_answers_20210130.csv\n",
      "outdoors_labels.pickle\n",
      "outdoors_question_answering_contexts.json\n",
      "outdoors_questionanswering_test_set.json\n",
      "outdoors_questionanswering_train_set.json\n",
      "._posts.csv\n",
      "posts.csv\n",
      "predicates.pickle\n",
      "pull_aips_dependency.py\n",
      "._question-answer-seed-contexts.csv\n",
      "question-answer-seed-contexts.csv\n",
      "question-answer-squad2-guesses.csv\n",
      "._roberta-base-squad2-outdoors\n",
      "roberta-base-squad2-outdoors/\n",
      "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/tokenizer_config.json\n",
      "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/special_tokens_map.json\n",
      "roberta-base-squad2-outdoors/._config.json\n",
      "roberta-base-squad2-outdoors/config.json\n",
      "roberta-base-squad2-outdoors/._merges.txt\n",
      "roberta-base-squad2-outdoors/merges.txt\n",
      "roberta-base-squad2-outdoors/._training_args.bin\n",
      "roberta-base-squad2-outdoors/training_args.bin\n",
      "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/pytorch_model.bin\n",
      "roberta-base-squad2-outdoors/._vocab.json\n",
      "roberta-base-squad2-outdoors/vocab.json\n"
     ]
    }
   ],
   "source": [
    "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
    "! cd outdoors && git pull\n",
    "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
    "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'\n",
    "\n",
    "#outdoors_collection = engine.create_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 1024\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "                            similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
    "                            truncate_dim=dimensions)\n",
    "\n",
    "def get_embeddings(texts, cache_name, ignore_cache=False):\n",
    "    cache_file_name = f\"data/embeddings/{cache_name}.pickle\"\n",
    "    if ignore_cache or not os.path.isfile(cache_file_name):        \n",
    "        #pool = model.start_multi_process_pool()\n",
    "        embeddings = model.encode(texts, normalize_embeddings=True)\n",
    "        #model.stop_multi_process_pool(pool)\n",
    "        #embeddings = model.encode(texts, convert_to_tensor=False).tolist()\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"wb\") as fd:\n",
    "            pickle.dump(embeddings, fd)\n",
    "    else:\n",
    "        with open(cache_file_name, \"rb\") as fd:\n",
    "            embeddings = pickle.load(fd)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.21\n",
    "### Generating embeddings and benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def calculate_outdoors_embeddings():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    embeddings = get_embeddings(post_texts, \"outdoors_mrl_normed\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    return numpy.array(embeddings), outdoors_data\n",
    "\n",
    "def display_results(scores, ids, data):\n",
    "    results = generate_search_results(scores, ids, data)\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "def calculate_stat_messages(full_search_time, time_taken, full_index_size, size):\n",
    "    if full_search_time:\n",
    "        t = round((full_search_time - time_taken) * 100 / full_search_time, 2)\n",
    "    improvement_ms = f\"({t}% improvement)\" if full_search_time else \"\"\n",
    "    improvement_size = f\"({round((full_index_size - size) * 100 / full_index_size, 2)}% improvement)\" if full_index_size else \"\"\n",
    "    return improvement_ms, improvement_size\n",
    "\n",
    "def generate_search_results(faiss_scores, faiss_ids, data):\n",
    "    scores = list(list(faiss_scores)[0])\n",
    "    ids = list(faiss_ids)\n",
    "    results = []\n",
    "    for i, id in enumerate(ids[0]):\n",
    "        id = int(id)\n",
    "        result = {\"score\": scores[i],\n",
    "                  \"title\": data[id][\"title\"],\n",
    "                  \"body\": data[id][\"body\"],\n",
    "                  \"id\": id}\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will generate and cache the embeddings. Takes 2-3 hours typically\n",
    "embeddings, outdoors_dataframe = calculate_outdoors_embeddings() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.22\n",
    "### int8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8 embeddings shape: (18456, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m int8_index \u001b[38;5;241m=\u001b[39m index_int_embeddings(embeddings, int8_index_name)\n\u001b[1;32m     62\u001b[0m quantized_queries \u001b[38;5;241m=\u001b[39m quantize_embeddings(query_embeddings,\n\u001b[1;32m     63\u001b[0m                                         calibration_embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m     64\u001b[0m                                         precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m scored_int8_results, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint8_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint8_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mquantized_queries\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 28\u001b[0m, in \u001b[0;36mevaluate_search\u001b[0;34m(index, index_name, embedded_query, k, log)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_search\u001b[39m(index, index_name, embedded_query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m     embeddings, outdoors_data \u001b[38;5;241m=\u001b[39m calculate_outdoors_embeddings()\n\u001b[0;32m---> 28\u001b[0m     scored_results, time_taken, size \u001b[38;5;241m=\u001b[39m \u001b[43mtime_and_execute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     full_search_results, full_search_time, full_index_size \u001b[38;5;241m=\u001b[39m execute_full_search(embeddings, query_embeddings, outdoors_data)\n\u001b[1;32m     30\u001b[0m     improvement_ms, improvement_size \u001b[38;5;241m=\u001b[39m calculate_stat_messages(full_search_time, time_taken,\n\u001b[1;32m     31\u001b[0m                                                                full_index_size, size)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mtime_and_execute_search\u001b[0;34m(index, index_name, embedded_query, k, log)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_and_execute_search\u001b[39m(index, index_name, embedded_query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 10\u001b[0m     _, outdoors_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_outdoors_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m     faiss_scores, faiss_ids \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(embedded_query, k\u001b[38;5;241m=\u001b[39mk) \n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mcalculate_outdoors_embeddings\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m post_texts \u001b[38;5;241m=\u001b[39m [post[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m post[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m outdoors_dataframe\u001b[38;5;241m.\u001b[39mcollect()]\n\u001b[1;32m      8\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m get_embeddings(post_texts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutdoors_mrl_normed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m outdoors_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43moutdoors_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39marray(embeddings), outdoors_data\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:1197\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1197\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "def index_embeddings(embeddings, name):\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def time_and_execute_search(index, index_name, embedded_query, k=25, log=False):\n",
    "    _, outdoors_data = calculate_outdoors_embeddings()\n",
    "    start_time = time.time()\n",
    "    faiss_scores, faiss_ids = index.search(embedded_query, k=k) \n",
    "    if log:\n",
    "        display(f\"Execute search scores: {faiss_scores}\")\n",
    "        display(f\"Search ids: {faiss_ids}\")\n",
    "    time_taken = ((time.time() - start_time) * 1000)\n",
    "    scored_results = generate_search_results(faiss_scores, faiss_ids, outdoors_data)\n",
    "    size = os.path.getsize(index_name)\n",
    "    return scored_results, time_taken, size\n",
    "\n",
    "def execute_full_search(embeddings, embedded_query, k=25):  \n",
    "    index_name = \"full_out_embs\"\n",
    "    full_index = index_embeddings(embeddings, index_name)\n",
    "    return time_and_execute_search(full_index, index_name, embedded_query, k=k)\n",
    "\n",
    "def evaluate_search(index, index_name, embedded_query, k=25, log=False):\n",
    "    embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "    scored_results, time_taken, size = time_and_execute_search(index, index_name, embedded_query, k=k)\n",
    "    full_search_results, full_search_time, full_index_size = execute_full_search(embeddings, query_embeddings, outdoors_data)\n",
    "    improvement_ms, improvement_size = calculate_stat_messages(full_search_time, time_taken,\n",
    "                                                               full_index_size, size)\n",
    "\n",
    "    calculate_recall(full_search_results, scored_int8_results)\n",
    "    print(f\"{index_name} search took: {time_taken:.3f} ms {improvement_ms}\")\n",
    "    print(f\"{index_name} index size: {round(size / 1000000, 2)} MB {improvement_size}\")\n",
    "    return scored_results, time_taken, size\n",
    "\n",
    "def calculate_recall(scored_full_results, scored_quantized_results):\n",
    "    full_ids = [r[\"id\"] for r in scored_full_results]\n",
    "    quantized_ids = [r[\"id\"] for r in scored_quantized_results]\n",
    "    recall =  (len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "               len(set(quantized_ids)))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "\n",
    "def index_int_embeddings(embeddings, name):\n",
    "    embeddings = quantize_embeddings(embeddings, precision=\"int8\")\n",
    "    print(\"Int8 embeddings shape:\", embeddings.shape)\n",
    "    index = faiss.IndexScalarQuantizer(embeddings.shape[1], faiss.ScalarQuantizer.QT_8bit)\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def get_test_queries():\n",
    "    return [\"tent poles\"]\n",
    "    \n",
    "embeddings, _ = calculate_outdoors_embeddings()\n",
    "int8_index_name = \"int8_out_embs\"\n",
    "queries = get_test_queries()\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "int8_index = index_int_embeddings(embeddings, int8_index_name)\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                                        calibration_embeddings=embeddings,\n",
    "                                        precision=\"int8\")\n",
    "scored_int8_results, _, _ = evaluate_search(int8_index, int8_index_name,\n",
    "                                           quantized_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8 embeddings shape: (18456, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 68\u001b[0m\n\u001b[1;32m     64\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(queries, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m quantized_queries \u001b[38;5;241m=\u001b[39m quantize_embeddings(query_embeddings,\n\u001b[1;32m     66\u001b[0m                                         calibration_embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m     67\u001b[0m                                         precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m scored_int8_results, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint8_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint8_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mquantized_queries\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m, in \u001b[0;36mevaluate_search\u001b[0;34m(index, index_name, embedded_query, k, log, full_search_time, full_index_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_search\u001b[39m(index, index_name, embedded_query,\n\u001b[1;32m     18\u001b[0m                     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, full_search_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, full_index_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     20\u001b[0m     embeddings, outdoors_data \u001b[38;5;241m=\u001b[39m calculate_outdoors_embeddings()\n\u001b[1;32m     21\u001b[0m     full_search_results, full_search_time, full_index_size \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 22\u001b[0m         \u001b[43mexecute_full_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdoors_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     25\u001b[0m     faiss_scores, faiss_ids \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(embedded_query, k) \n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36mexecute_full_search\u001b[0;34m(embeddings, embedded_query, outdoors_data)\u001b[0m\n\u001b[1;32m     11\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_out_embs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m full_index \u001b[38;5;241m=\u001b[39m index_embeddings(embeddings, index_name)\n\u001b[0;32m---> 13\u001b[0m scored_full_results, time, size \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdoors_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scored_full_results, time, size\n",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m, in \u001b[0;36mevaluate_search\u001b[0;34m(index, index_name, embedded_query, k, log, full_search_time, full_index_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_search\u001b[39m(index, index_name, embedded_query,\n\u001b[1;32m     18\u001b[0m                     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, full_search_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, full_index_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     20\u001b[0m     embeddings, outdoors_data \u001b[38;5;241m=\u001b[39m calculate_outdoors_embeddings()\n\u001b[1;32m     21\u001b[0m     full_search_results, full_search_time, full_index_size \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 22\u001b[0m         \u001b[43mexecute_full_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdoors_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     25\u001b[0m     faiss_scores, faiss_ids \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msearch(embedded_query, k) \n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36mexecute_full_search\u001b[0;34m(embeddings, embedded_query, outdoors_data)\u001b[0m\n\u001b[1;32m     11\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_out_embs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m full_index \u001b[38;5;241m=\u001b[39m index_embeddings(embeddings, index_name)\n\u001b[0;32m---> 13\u001b[0m scored_full_results, time, size \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdoors_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scored_full_results, time, size\n",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m, in \u001b[0;36mevaluate_search\u001b[0;34m(index, index_name, embedded_query, k, log, full_search_time, full_index_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_search\u001b[39m(index, index_name, embedded_query,\n\u001b[1;32m     18\u001b[0m                     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, full_search_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, full_index_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     embeddings, outdoors_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_outdoors_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     full_search_results, full_search_time, full_index_size \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     22\u001b[0m         execute_full_search(embeddings, embedded_query, outdoors_data)\n\u001b[1;32m     24\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mcalculate_outdoors_embeddings\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m post_texts \u001b[38;5;241m=\u001b[39m [post[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m post[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m outdoors_dataframe\u001b[38;5;241m.\u001b[39mcollect()]\n\u001b[1;32m      8\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m get_embeddings(post_texts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutdoors_mrl_normed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m outdoors_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43moutdoors_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39marray(embeddings), outdoors_data\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:1197\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1197\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "def index_embeddings(embeddings, name):\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def execute_full_search(embeddings, embedded_query, outdoors_data):    \n",
    "    embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "    index_name = \"full_out_embs\"\n",
    "    full_index = index_embeddings(embeddings, index_name)\n",
    "    scored_full_results, time, size = evaluate_search(full_index, index_name,\n",
    "                                                     embedded_query, outdoors_data)\n",
    "    return scored_full_results, time, size\n",
    "\n",
    "def evaluate_search(index, index_name, embedded_query,\n",
    "                    k=25, log=False, full_search_time=None, full_index_size=None):\n",
    "    \n",
    "    embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "    full_search_results, full_search_time, full_index_size = \\\n",
    "        execute_full_search(embeddings, embedded_query, outdoors_data)\n",
    "\n",
    "    start_time = time.time()\n",
    "    faiss_scores, faiss_ids = index.search(embedded_query, k) \n",
    "    time_taken = ((time.time() - start_time) * 1000)\n",
    "    size = os.path.getsize(index_name)\n",
    "    improvement_ms, improvement_size = calculate_stat_messages(full_search_time, time_taken,\n",
    "                                                               full_index_size, size)\n",
    "    print(f\"{index_name} search took: {time_taken:.3f} ms {improvement_ms}\")\n",
    "    print(f\"{index_name} index size: {round(size / 1000000, 2)} MB {improvement_size}\")\n",
    "    if log:\n",
    "        display(f\"Execute search scores: {faiss_scores}\")\n",
    "        display(f\"Search ids: {faiss_ids}\")\n",
    "        \n",
    "    scored_results = generate_search_results(faiss_scores, faiss_ids, outdoors_data)\n",
    "\n",
    "    calculate_recall(full_search_results, scored_int8_results)\n",
    "    return scored_results, time_taken, size\n",
    "\n",
    "def calculate_recall(scored_full_results, scored_quantized_results):\n",
    "    full_ids = [r[\"id\"] for r in scored_full_results]\n",
    "    quantized_ids = [r[\"id\"] for r in scored_quantized_results]\n",
    "    recall =  (len(set(full_ids).intersection(set(quantized_ids))) /\n",
    "               len(set(quantized_ids)))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "\n",
    "def index_int_embeddings(embeddings, name):\n",
    "    embeddings = quantize_embeddings(embeddings, precision=\"int8\")\n",
    "    print(\"Int8 embeddings shape:\", embeddings.shape)\n",
    "    index = faiss.IndexScalarQuantizer(embeddings.shape[1], faiss.ScalarQuantizer.QT_8bit)\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def get_test_queries():\n",
    "    return [\"tent poles\"]\n",
    "\n",
    "int8_index_name = \"int8_out_embs\"\n",
    "embeddings, _ = calculate_outdoors_embeddings()\n",
    "int8_index = index_int_embeddings(embeddings, int8_index_name)\n",
    "queries = get_test_queries()\n",
    "query_embeddings = model.encode(queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "quantized_queries = quantize_embeddings(query_embeddings,\n",
    "                                        calibration_embeddings=embeddings,\n",
    "                                        precision=\"int8\")\n",
    "scored_int8_results, _, _ = evaluate_search(int8_index, int8_index_name,\n",
    "                                            query_embeddings,\n",
    "                                            quantized_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.23\n",
    "### Binary Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary embeddings shape: (18456, 128)\n",
      "binary_out_embs search took: 754.192 ms (-12400.24% improvement)\n",
      "binary_out_embs index size: 2.36 MB (96.87% improvement)\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "def binary_quantize_embeddings(embeddings):\n",
    "    #quantized_embs = numpy.where(embeddings < 0, 0, 1).astype(numpy.uint8) # binarize\n",
    "    return numpy.packbits(embeddings > 0).reshape(embeddings.shape[0], -1)\n",
    "    \n",
    "def index_binary_embeddings(embeddings):\n",
    "    binary_embeddings = numpy.packbits(embeddings > 0).reshape(embeddings.shape[0], -1)\n",
    "    print(\"Binary embeddings shape:\", binary_embeddings.shape)\n",
    "    index = faiss.IndexBinaryFlat(binary_embeddings.shape[1] * 8)\n",
    "    index.add(binary_embeddings)\n",
    "    faiss.write_index_binary(index, \"binary_out_embs\")\n",
    "    return index\n",
    "\n",
    "binary_index = index_binary_embeddings(embeddings)\n",
    "quantized_query = numpy.packbits(embeddings > 0).reshape(embeddings.shape[0], -1)\n",
    "scored_binary_results, _, _ = execute_search(binary_index, \"binary_out_embs\",\n",
    "                                             quantized_query, outdoors_data,\n",
    "                                             log=False,\n",
    "                                             full_search_time=full_search_time,\n",
    "                                             full_index_size=full_index_size)\n",
    "calculate_recall(scored_full_results, scored_binary_results)\n",
    "# (vs. 5.000 ms, 90% reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.24\n",
    "### Matroyoshka Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_out_embs search took: 3.799 ms \n",
      "full_out_embs index size: 75.6 MB \n",
      "MRL512 embeddings shape: (18456, 512)\n",
      "mrl_out_embs_512 search took: 1.930 ms (49.21% improvement)\n",
      "mrl_out_embs_512 index size: 37.8 MB (50.0% improvement)\n",
      "Recall: 0.84\n",
      "MRL256 embeddings shape: (18456, 256)\n",
      "mrl_out_embs_256 search took: 1.014 ms (73.31% improvement)\n",
      "mrl_out_embs_256 index size: 18.9 MB (75.0% improvement)\n",
      "Recall: 0.64\n",
      "MRL128 embeddings shape: (18456, 128)\n",
      "mrl_out_embs_128 search took: 0.582 ms (84.69% improvement)\n",
      "mrl_out_embs_128 index size: 9.45 MB (87.5% improvement)\n",
      "Recall: 0.52\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mrl_quantized_searches(query):\n",
    "    embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "    query_embeddings = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    scored_full_results, full_search_time, full_index_size = \\\n",
    "        execute_full_search(embeddings, query_embeddings, outdoors_data)\n",
    "    for slice in [512, 256, 128]:\n",
    "        index_name = f\"mrl_out_embs_{slice}\"\n",
    "        scaled_embeddings = numpy.array(list(map(lambda e: e[:slice], embeddings)))\n",
    "        print(f\"MRL{slice} embeddings shape:\", scaled_embeddings.shape)\n",
    "        index = index_embeddings(scaled_embeddings, index_name)\n",
    "        quantized_query = numpy.array(list(map(lambda qe: qe[:slice], query_embeddings)))\n",
    "        scored_results, _, _ = execute_search(index, index_name,\n",
    "                                              quantized_query, outdoors_data,\n",
    "                                              full_search_time=full_search_time,\n",
    "                                              full_index_size=full_index_size)        \n",
    "        calculate_recall(scored_full_results, scored_results)\n",
    "\n",
    "evaluate_mrl_quantized_searches(\"tent poles\")\n",
    "\n",
    "#full_out_embs search took: 3.900 ms\n",
    "#full_out_embs index size: 75,595,821 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.25\n",
    "### Product quantizationQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_out_embs search took: 4.253 ms \n",
      "full_out_embs index size: 75.6 MB \n",
      "pq_out_embs search took: 0.538 ms (87.35% improvement)\n",
      "pq_out_embs index size: 76.79 MB (-1.58% improvement)\n",
      "Recall: 0.28\n"
     ]
    }
   ],
   "source": [
    "def index_pq_embeddings(embeddings, name=\"pq_out_embs\"):    \n",
    "    dimensions = embeddings.shape[1]\n",
    "    sub_vectors = 8\n",
    "    subquantizer_bits = 8\n",
    "    #faiss::IndexIVFPQ, IndexIVFPQR\n",
    "    index = faiss.IndexPQ(dimensions, sub_vectors, subquantizer_bits)\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, name)\n",
    "    return index\n",
    "\n",
    "def index_pq_reranked_embeddings(embeddings, name=\"pq_out_embs\"):    \n",
    "    dimensions = embeddings.shape[1]\n",
    "    sub_vectors = 8\n",
    "    subquantizer_bits = 8\n",
    "    #faiss::IndexIVFPQ, IndexIVFPQR\n",
    "    index = faiss.IndexPQ(dimensions, sub_vectors, subquantizer_bits)\n",
    "    rereanking_pq_index = faiss.IndexRefineFlat(index)\n",
    "    rereanking_pq_index.train(embeddings)\n",
    "    rereanking_pq_index.add(embeddings)\n",
    "    faiss.write_index(rereanking_pq_index, name)\n",
    "    return index\n",
    "\n",
    "embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "query_embeddings = model.encode([\"Hiking trails\"], convert_to_numpy=True, normalize_embeddings=True)\n",
    "scored_full_results, full_search_time, full_index_size = \\\n",
    "    execute_full_search(embeddings, query_embeddings, outdoors_data)\n",
    "embeddings, outdoors_data = calculate_outdoors_embeddings()\n",
    "index = index_pq_reranked_embeddings(embeddings)\n",
    "scored_results, _, _ = execute_search(index, \"pq_out_embs\", query_embeddings, outdoors_data,\n",
    "                                   full_search_time=full_search_time,\n",
    "                                   full_index_size=full_index_size)\n",
    "calculate_recall(scored_full_results, scored_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.26\n",
    "### Quantization and reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m     results \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbinary_request)\n\u001b[1;32m     69\u001b[0m     display(results)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mbuild_engine_quantization_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m collection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutdoors_quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m engine_rankings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhiking trails\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m, in \u001b[0;36mbuild_engine_quantization_index\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_engine_quantization_index\u001b[39m():\n\u001b[0;32m---> 22\u001b[0m     outdoors_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_outdoors_embeddingsss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     schema \u001b[38;5;241m=\u001b[39m StructType([StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType()),\n\u001b[1;32m     24\u001b[0m                          StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType()),\n\u001b[1;32m     25\u001b[0m                          StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, ArrayType(FloatType())),\n\u001b[1;32m     26\u001b[0m                          StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_text_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, ArrayType(ByteType()))])\n\u001b[1;32m     27\u001b[0m     outdoors_dataframe \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[1;32m     28\u001b[0m         [Row(title\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m], body\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     29\u001b[0m              text_embedding\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m              binary_text_embedding\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_text_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     31\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m outdoors_data], schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mcalculate_outdoors_embeddingsss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     outdoors_data[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embs\n\u001b[1;32m     15\u001b[0m     asdf \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(embs)\n\u001b[1;32m     16\u001b[0m     outdoors_data[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_text_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpackbits\u001b[49m\u001b[43m(\u001b[49m\u001b[43masdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43masdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     18\u001b[0m     [\u001b[38;5;28mfloat\u001b[39m(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings[i]]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outdoors_data\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf, monotonically_increasing_id\n",
    "from pyspark.sql.types import Row, ArrayType, FloatType, StructField, StructType, StringType, ByteType\n",
    "import faiss\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "\n",
    "def calculate_outdoors_embeddingsss():\n",
    "    outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    post_texts = [post[\"title\"] + \" \" + post[\"body\"]\n",
    "                  for post in outdoors_dataframe.collect()]\n",
    "    embeddings = get_embeddings(post_texts, \"outdoors_mrl_normed\")\n",
    "    outdoors_data = list(outdoors_dataframe.rdd.map(lambda r: r.asDict()).collect())\n",
    "    for i in range(len(outdoors_data)):\n",
    "        embs = [float(e) for e in embeddings[i]]\n",
    "        outdoors_data[i][\"text_embedding\"] = embs\n",
    "        asdf = numpy.array(embs)\n",
    "        outdoors_data[i][\"binary_text_embedding\"] = numpy.packbits(embs > 0) \\\n",
    "            .reshape(asdf, -1).tolist()\n",
    "        [float(e) for e in embeddings[i]]\n",
    "    return outdoors_data\n",
    "\n",
    "def build_engine_quantization_index():\n",
    "    outdoors_data = calculate_outdoors_embeddingsss()\n",
    "    schema = StructType([StructField(\"title\", StringType()),\n",
    "                         StructField(\"body\", StringType()),\n",
    "                         StructField(\"text_embedding\", ArrayType(FloatType())),\n",
    "                         StructField(\"binary_text_embedding\", ArrayType(ByteType()))])\n",
    "    outdoors_dataframe = spark.createDataFrame(\n",
    "        [Row(title=x[\"title\"], body=x[\"body\"],\n",
    "             text_embedding=x[\"text_embedding\"],\n",
    "             binary_text_embedding=x[\"binary_text_embedding\"])\n",
    "             for x in outdoors_data], schema=schema)\n",
    "    #embeddings = list(embeddings)\n",
    "    #outdoors_data = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "    #quantized_embeddings = [quantize(e) for e in normalized_embeddings]\n",
    "    embeddings_collection = engine.create_collection(\"outdoors_quantization\")\n",
    "    #outdoors_data = outdoors_data.withColumn(\"id\", monotonically_increasing_id())\n",
    "    #outdoors_data = outdoors_data.withColumn(\"text_embedding\",\n",
    "                                             #udf(lambda id: [float(e) for e in embeddings.pop(0)],\n",
    "                                                 #ArrayType(FloatType()))(\"id\"))\n",
    "    #outdoors_data = outdoors_data.withColumn(\"binary_text_embedding\")\n",
    "    print(type(outdoors_dataframe))\n",
    "    embeddings_collection.write(outdoors_dataframe)\n",
    "\n",
    "def search_request(query_vector, field, rerank_vector, rerank_field,\n",
    "                          quantization_size):\n",
    "    return {\"query\": query_vector,\n",
    "            \"query_fields\": [field],\n",
    "            \"return_fields\": [\"title\", \"body\"],\n",
    "            \"limit\": 25,\n",
    "            \"k\": 1000,\n",
    "            #\"rerank_query\": {\"rerank_count\": 250,\n",
    "            #                 \"query\": rerank_vector,\n",
    "            #                 \"query_fields\": [field],\n",
    "            #                 \"k\": 25},\n",
    "            \"quantization_size\": quantization_size,\n",
    "            \"log\": True}\n",
    "\n",
    "def engine_rankings(query, log=False):\n",
    "    collection = engine.get_collection(\"outdoors_quantization\")\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    #quantized_query = numpy.zeros_like(query_embedding, dtype=numpy.int8)\n",
    "    #quantized_query[query_embedding > 0] = 1\n",
    "    quantized_query = numpy.packbits(query_embedding > 0).reshape(embeddings.query_embedding[0], -1)\n",
    "\n",
    "    binary_request = search_request(quantized_query[0].tolist(), \"binary_text_embedding\",\n",
    "                                    query_embedding[0].tolist(), \"text_embedding\",\n",
    "                                    \"BINARY\")\n",
    "    results = collection.search(**binary_request)\n",
    "    display(results)\n",
    "\n",
    "build_engine_quantization_index()\n",
    "collection = engine.get_collection(\"outdoors_quantization\")\n",
    "engine_rankings(\"hiking trails\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
